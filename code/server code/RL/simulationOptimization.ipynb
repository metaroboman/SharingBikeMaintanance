{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [00:21<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning over\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This part of code is the Deep Q Network (DQN) brain.\n",
    "view the tensorboard picture about this DQN structure on: https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/4-3-DQN3/#modification\n",
    "View more on my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "Using:\n",
    "Tensorflow: r1.2\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "\n",
    "# Deep Q Network off-policy\n",
    "class DeepQNetwork:\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_actions,\n",
    "            n_features,\n",
    "            learning_rate=0.01,\n",
    "            reward_decay=0.9,\n",
    "            e_greedy=0.9,\n",
    "            replace_target_iter=300,\n",
    "            memory_size=500,\n",
    "            batch_size=32,\n",
    "            e_greedy_increment=None,\n",
    "            output_graph=False,\n",
    "    ):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_features = n_features\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon_max = e_greedy\n",
    "        self.replace_target_iter = replace_target_iter\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon_increment = e_greedy_increment\n",
    "        self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max\n",
    "\n",
    "        # total learning step\n",
    "        self.learn_step_counter = 0\n",
    "\n",
    "        # initialize zero memory [s, a, r, s_]\n",
    "        self.memory = np.zeros((self.memory_size, n_features * 2 + 2))\n",
    "\n",
    "        # consist of [target_net, evaluate_net]\n",
    "        self._build_net()\n",
    "\n",
    "        t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target_net')\n",
    "        e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='eval_net')\n",
    "\n",
    "        with tf.variable_scope('hard_replacement'):\n",
    "            self.target_replace_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        if output_graph:\n",
    "            # $ tensorboard --logdir=logs\n",
    "            tf.summary.FileWriter(\"logs/\", self.sess.graph)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.cost_his = []\n",
    "\n",
    "    def _build_net(self):\n",
    "        # ------------------ all inputs ------------------------\n",
    "        self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')  # input State\n",
    "        self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name='s_')  # input Next State\n",
    "        self.r = tf.placeholder(tf.float32, [None, ], name='r')  # input Reward\n",
    "        self.a = tf.placeholder(tf.int32, [None, ], name='a')  # input Action\n",
    "\n",
    "        w_initializer, b_initializer = tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)\n",
    "\n",
    "        # ------------------ build evaluate_net ------------------\n",
    "        with tf.variable_scope('eval_net'):\n",
    "            e1 = tf.layers.dense(self.s, 20, tf.nn.relu, kernel_initializer=w_initializer,\n",
    "                                 bias_initializer=b_initializer, name='e1')\n",
    "            self.q_eval = tf.layers.dense(e1, self.n_actions, kernel_initializer=w_initializer,\n",
    "                                          bias_initializer=b_initializer, name='q')\n",
    "\n",
    "        # ------------------ build target_net ------------------\n",
    "        with tf.variable_scope('target_net'):\n",
    "            t1 = tf.layers.dense(self.s_, 20, tf.nn.relu, kernel_initializer=w_initializer,\n",
    "                                 bias_initializer=b_initializer, name='t1')\n",
    "            self.q_next = tf.layers.dense(t1, self.n_actions, kernel_initializer=w_initializer,\n",
    "                                          bias_initializer=b_initializer, name='t2')\n",
    "\n",
    "        with tf.variable_scope('q_target'):\n",
    "            q_target = self.r + self.gamma * tf.reduce_max(self.q_next, axis=1, name='Qmax_s_')    # shape=(None, )\n",
    "            self.q_target = tf.stop_gradient(q_target)\n",
    "        with tf.variable_scope('q_eval'):\n",
    "            a_indices = tf.stack([tf.range(tf.shape(self.a)[0], dtype=tf.int32), self.a], axis=1)\n",
    "            self.q_eval_wrt_a = tf.gather_nd(params=self.q_eval, indices=a_indices)    # shape=(None, )\n",
    "        with tf.variable_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval_wrt_a, name='TD_error'))\n",
    "        with tf.variable_scope('train'):\n",
    "            self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        if not hasattr(self, 'memory_counter'):\n",
    "            self.memory_counter = 0\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        # to have batch dimension when feed into tf placeholder\n",
    "        observation = observation[np.newaxis, :]\n",
    "\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # forward feed the observation and get q value for every actions\n",
    "            actions_value = self.sess.run(self.q_eval, feed_dict={self.s: observation})\n",
    "            action = np.argmax(actions_value)\n",
    "        else:\n",
    "            action = np.random.randint(0, self.n_actions)\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        # check to replace target parameters\n",
    "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
    "            self.sess.run(self.target_replace_op)\n",
    "            #print('\\ntarget_params_replaced\\n')\n",
    "\n",
    "        # sample batch memory from all memory\n",
    "        if self.memory_counter > self.memory_size:\n",
    "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "        else:\n",
    "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
    "        batch_memory = self.memory[sample_index, :]\n",
    "\n",
    "        _, cost = self.sess.run(\n",
    "            [self._train_op, self.loss],\n",
    "            feed_dict={\n",
    "                self.s: batch_memory[:, :self.n_features],\n",
    "                self.a: batch_memory[:, self.n_features],\n",
    "                self.r: batch_memory[:, self.n_features + 1],\n",
    "                self.s_: batch_memory[:, -self.n_features:],\n",
    "            })\n",
    "\n",
    "        self.cost_his.append(cost)\n",
    "\n",
    "        # increasing epsilon\n",
    "        self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon < self.epsilon_max else self.epsilon_max\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "    def plot_cost(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(np.arange(len(self.cost_his)), self.cost_his)\n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('training steps')\n",
    "        plt.show()\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     DQN = DeepQNetwork(3,4, output_graph=True)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Area():\n",
    "    def __init__(self, n, a_id):\n",
    "        self.a_id = a_id\n",
    "        self.normal_bike = n\n",
    "        self.broken_bike = 0\n",
    "\n",
    "    def move(self):\n",
    "        self.normal_bike -= 1\n",
    "        self.broken_bike += 1\n",
    "        \n",
    "    def repair(self):\n",
    "        self.normal_bike += 1\n",
    "        self.broken_bike -= 1\n",
    "\n",
    "\n",
    "def binaryInsert(target, events):\n",
    "    for event in events:\n",
    "        if event >= target[-1]:\n",
    "            target.append(event)\n",
    "        else:\n",
    "            l, mid, r = 0, int(len(target) / 2), len(target) - 1\n",
    "            while 1:\n",
    "                if r - l == 1:\n",
    "                    target.insert(r, event)\n",
    "                    break\n",
    "                else:\n",
    "                    if event > target[mid]:\n",
    "                        l = mid\n",
    "                        mid = int((r + l) / 2)\n",
    "                    else:\n",
    "                        r = mid\n",
    "                        mid = int((r + l) / 2)\n",
    "\n",
    "\n",
    "class BikeNet():\n",
    "    def __init__(self, N, R, A, Q, repair, P, time_limit):\n",
    "        self.N = N\n",
    "        self.R = R\n",
    "        self.A = A\n",
    "        self.Q = Q\n",
    "        self.repair = repair\n",
    "        self.P = P\n",
    "        self.time_limit = time_limit\n",
    "        self.reset()\n",
    "        self.trans = {}\n",
    "\n",
    "    def reset(self):\n",
    "        # self.__init__(self.N, self.R, self.A, self.Q, self.P, self.time_limit)\n",
    "        # stat, S = pd.DataFrame(columns=['type', 'place', 't']), 0\n",
    "        # loss, L = pd.DataFrame(columns=['place', 't']), 0\n",
    "        # broken, B = pd.DataFrame(columns=['place', 'ng', 'nb', 't']), 0\n",
    "\n",
    "        # initiation of instances of Area and scheduler\n",
    "        self.T = 0\n",
    "        self.carrier_position = 0\n",
    "        self.scheduler = []\n",
    "        self.a = []  # list of instances of areas\n",
    "        self.s = np.array([(self.N / self.A) if i % 2 == 0 else 0 for i in range(2 * self.A)])\n",
    "        for i in range(A):\n",
    "            self.a.append(Area(self.N / self.A, i))\n",
    "            self.scheduler.append([np.random.exponential(1 / self.R.loc[i].cus_arr), 1, self.a[i]])\n",
    "        self.scheduler.sort()\n",
    "\n",
    "        return self.s.copy()\n",
    "\n",
    "    def step(self, action):\n",
    "        # time for carrier to take the action and repair one bicycle\n",
    "        t = (np.abs(self.carrier_position % 3 - action % 3) + np.abs(self.carrier_position // 3 - action // 3)) / \\\n",
    "            self.R.loc[0].ride + self.repair\n",
    "        t_cursor = self.T + t\n",
    "        self.carrier_position = action\n",
    "        reward = 0\n",
    "\n",
    "        # update the atate of QN during the tansformation time\n",
    "        while self.T < t_cursor:\n",
    "            self.T = self.scheduler[0][0]\n",
    "            if self.scheduler[0][1] == 1:\n",
    "                # stat.loc[S], S = [scheduler[0][1], scheduler[0][2].a_id, T], S+1\n",
    "                if self.scheduler[0][2].normal_bike == 0:\n",
    "                    # this is a loss\n",
    "                    reward -= 1\n",
    "                    # loss.loc[L], L = [scheduler[0][2].a_id, self.T], L+1\n",
    "                    event = [self.T + np.random.exponential(1 / self.R.loc[self.scheduler[0][2].a_id].cus_arr), 1,\n",
    "                             self.scheduler[0][2]]\n",
    "                    binaryInsert(self.scheduler, [event])\n",
    "                else:\n",
    "                    target = np.random.choice(np.arange(self.A + 1), 1, p=self.Q[self.scheduler[0][2].a_id])\n",
    "                    if target == self.A:\n",
    "                        # broken.loc[B], B = [self.scheduler[0][2].a_id, self.scheduler[0][2].normal_bike, self.scheduler[0][2].broken_bike, T], B+1\n",
    "                        self.scheduler[0][2].move()\n",
    "                        self.s[self.scheduler[0][2].a_id * 2], self.s[self.scheduler[0][2].a_id * 2 + 1] = \\\n",
    "                        self.scheduler[0][2].normal_bike, self.scheduler[0][2].broken_bike\n",
    "                        continue\n",
    "                    else:\n",
    "                        self.scheduler[0][2].normal_bike -= 1\n",
    "                        self.s[self.scheduler[0][2].a_id * 2] -= 1\n",
    "                        event1 = [self.T + np.random.exponential(1 / self.R.loc[self.scheduler[0][2].a_id].ride), 2,\n",
    "                                  self.a[target[0]]]\n",
    "                        event2 = [self.T + np.random.exponential(1 / self.R.loc[self.scheduler[0][2].a_id].cus_arr), 1,\n",
    "                                  self.scheduler[0][2]]\n",
    "                        binaryInsert(self.scheduler, [event1, event2])\n",
    "            else:\n",
    "                # stat.loc[S], S = [scheduler[0][1], scheduler[0][2].a_id, T], S+1\n",
    "                self.scheduler[0][2].normal_bike += 1\n",
    "                self.s[self.scheduler[0][2].a_id * 2] += 1\n",
    "            self.scheduler.pop(0)\n",
    "        \n",
    "        self.a[action].repair()\n",
    "        s_ = self.s.copy()\n",
    "\n",
    "        self.T = t_cursor\n",
    "        if self.T < self.time_limit:\n",
    "            return s_, reward, 0\n",
    "        else:\n",
    "            return s_, reward, 1\n",
    "\n",
    "# from maze_env import Maze\n",
    "# from RL_brain import DeepQNetwork\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "@jit\n",
    "def simulate():\n",
    "    #\n",
    "    n_episodes = 5\n",
    "    result = []\n",
    "    for episode in tqdm(range(n_episodes)):\n",
    "        step = 0\n",
    "        sum_r = 0\n",
    "        # initial observation\n",
    "        observation = env.reset()\n",
    "        action = 0\n",
    "        #observation = np.array(int(N/A)) #devide all the normal bikes to all the areas evenly at the beginning\n",
    "\n",
    "        while True:\n",
    "            # fresh env\n",
    "            #env.render()\n",
    "\n",
    "            # RL choose action based on observation\n",
    "            #if not env.a[action].broken_bike:\n",
    "            action = RL.choose_action(observation)\n",
    "            #    action = (action+1)%A\n",
    "\n",
    "            # RL take action and get next observation and reward\n",
    "            observation_, reward, done = env.step(action)\n",
    "\n",
    "            RL.store_transition(observation, action, reward, observation_)\n",
    "\n",
    "            if (step > 200) and (step % 5 == 0):\n",
    "                RL.learn()\n",
    "            #RL.learn()\n",
    "\n",
    "            # swap observation\n",
    "            observation = observation_\n",
    "\n",
    "            # break while loop when end of this episode\n",
    "            if done:\n",
    "                break\n",
    "            #step += 1\n",
    "            sum_r += reward\n",
    "            \n",
    "        result.append([episode, sum_r])\n",
    "\n",
    "    # end of game\n",
    "    print('learning over')\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # maze game\n",
    "    np.random.seed(1)\n",
    "    N = 80 #total number of bikes in the QN\n",
    "    A = 4 #A for areas, indicates the aumber of areas and the action space\n",
    "    R = pd.DataFrame({'cus_arr': [1] * A, 'ride': [0.5] * A}, index=range(A))\n",
    "    Q = [np.random.rand(A) for i in range(A)]\n",
    "    Q = [q / sum(q)*0.99 for q in Q]\n",
    "    Q = [np.append(q, 0.01) for q in Q]\n",
    "    #Q = [[0,0.9,0.1], [0.9,0,0.1]]\n",
    "    t_repair = 5\n",
    "    P = 0\n",
    "    time_limit = 1800\n",
    "\n",
    "    env = BikeNet(N, R, A, Q, t_repair, P, time_limit)\n",
    "    \n",
    "    RL = DeepQNetwork(A, 2*A,\n",
    "                      learning_rate=0.01,\n",
    "                      reward_decay=0.9,\n",
    "                      e_greedy=0.9,\n",
    "                      replace_target_iter=200,\n",
    "                      memory_size=2000,\n",
    "                      # output_graph=True\n",
    "                      )\n",
    "    output = simulate()\n",
    "    #RL.plot_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1736.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.array(output)\n",
    "output[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(output, columns = ['index', 'reward'])\n",
    "result.to_csv('C:/Rebalancing/data/result/baseline_4_80_500_local.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2021.51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2460.721257069695"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acemec\\Anaconda3\\envs\\rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\acemec\\Anaconda3\\envs\\rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\acemec\\Anaconda3\\envs\\rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\acemec\\Anaconda3\\envs\\rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:474: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\acemec\\Anaconda3\\envs\\rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:475: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The double DQN based on this paper: https://arxiv.org/abs/1509.06461\n",
    "View more on my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "Using:\n",
    "Tensorflow: 1.0\n",
    "gym: 0.8.0\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "\n",
    "class DoubleDQN:\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_actions,\n",
    "            n_features,\n",
    "            learning_rate=0.005,\n",
    "            reward_decay=0.9,\n",
    "            e_greedy=0.9,\n",
    "            replace_target_iter=200,\n",
    "            memory_size=3000,\n",
    "            batch_size=32,\n",
    "            e_greedy_increment=None,\n",
    "            output_graph=False,\n",
    "            double_q=True,\n",
    "            sess=None,\n",
    "    ):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_features = n_features\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon_max = e_greedy\n",
    "        self.replace_target_iter = replace_target_iter\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon_increment = e_greedy_increment\n",
    "        self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max\n",
    "\n",
    "        self.double_q = double_q    # decide to use double q or not\n",
    "\n",
    "        self.learn_step_counter = 0\n",
    "        self.memory = np.zeros((self.memory_size, n_features*2+2))\n",
    "        self._build_net()\n",
    "        t_params = tf.get_collection('target_net_params')\n",
    "        e_params = tf.get_collection('eval_net_params')\n",
    "        self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]\n",
    "\n",
    "        if sess is None:\n",
    "            self.sess = tf.Session()\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "        else:\n",
    "            self.sess = sess\n",
    "        if output_graph:\n",
    "            tf.summary.FileWriter(\"logs/\", self.sess.graph)\n",
    "        self.cost_his = []\n",
    "\n",
    "    def _build_net(self):\n",
    "        def build_layers(s, c_names, n_l1, w_initializer, b_initializer):\n",
    "            with tf.variable_scope('l1'):\n",
    "                w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names)\n",
    "                b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names)\n",
    "                l1 = tf.nn.relu(tf.matmul(s, w1) + b1)\n",
    "\n",
    "            with tf.variable_scope('l2'):\n",
    "                w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)\n",
    "                b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n",
    "                out = tf.matmul(l1, w2) + b2\n",
    "            return out\n",
    "        # ------------------ build evaluate_net ------------------\n",
    "        self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')  # input\n",
    "        self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q_target')  # for calculating loss\n",
    "\n",
    "        with tf.variable_scope('eval_net'):\n",
    "            c_names, n_l1, w_initializer, b_initializer = \\\n",
    "                ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 20, \\\n",
    "                tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)  # config of layers\n",
    "\n",
    "            self.q_eval = build_layers(self.s, c_names, n_l1, w_initializer, b_initializer)\n",
    "\n",
    "        with tf.variable_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))\n",
    "        with tf.variable_scope('train'):\n",
    "            self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "        # ------------------ build target_net ------------------\n",
    "        self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name='s_')    # input\n",
    "        with tf.variable_scope('target_net'):\n",
    "            c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "\n",
    "            self.q_next = build_layers(self.s_, c_names, n_l1, w_initializer, b_initializer)\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        if not hasattr(self, 'memory_counter'):\n",
    "            self.memory_counter = 0\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        observation = observation[np.newaxis, :]\n",
    "        actions_value = self.sess.run(self.q_eval, feed_dict={self.s: observation})\n",
    "        action = np.argmax(actions_value)\n",
    "\n",
    "        if not hasattr(self, 'q'):  # record action value it gets\n",
    "            self.q = []\n",
    "            self.running_q = 0\n",
    "        self.running_q = self.running_q*0.99 + 0.01 * np.max(actions_value)\n",
    "        self.q.append(self.running_q)\n",
    "\n",
    "        if np.random.uniform() > self.epsilon:  # choosing action\n",
    "            action = np.random.randint(0, self.n_actions)\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
    "            self.sess.run(self.replace_target_op)\n",
    "            print('\\ntarget_params_replaced\\n')\n",
    "\n",
    "        if self.memory_counter > self.memory_size:\n",
    "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "        else:\n",
    "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
    "        batch_memory = self.memory[sample_index, :]\n",
    "\n",
    "        q_next, q_eval4next = self.sess.run(\n",
    "            [self.q_next, self.q_eval],\n",
    "            feed_dict={self.s_: batch_memory[:, -self.n_features:],    # next observation\n",
    "                       self.s: batch_memory[:, -self.n_features:]})    # next observation\n",
    "        q_eval = self.sess.run(self.q_eval, {self.s: batch_memory[:, :self.n_features]})\n",
    "\n",
    "        q_target = q_eval.copy()\n",
    "\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        eval_act_index = batch_memory[:, self.n_features].astype(int)\n",
    "        reward = batch_memory[:, self.n_features + 1]\n",
    "\n",
    "        if self.double_q:\n",
    "            max_act4next = np.argmax(q_eval4next, axis=1)        # the action that brings the highest value is evaluated by q_eval\n",
    "            selected_q_next = q_next[batch_index, max_act4next]  # Double DQN, select q_next depending on above actions\n",
    "        else:\n",
    "            selected_q_next = np.max(q_next, axis=1)    # the natural DQN\n",
    "\n",
    "        q_target[batch_index, eval_act_index] = reward + self.gamma * selected_q_next\n",
    "\n",
    "        _, self.cost = self.sess.run([self._train_op, self.loss],\n",
    "                                     feed_dict={self.s: batch_memory[:, :self.n_features],\n",
    "                                                self.q_target: q_target})\n",
    "        self.cost_his.append(self.cost)\n",
    "\n",
    "        self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon < self.epsilon_max else self.epsilon_max\n",
    "        self.learn_step_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-08-13 14:28:49,326] Making new env: Pendulum-v0\n",
      "C:\\Users\\acemec\\Anaconda3\\envs\\rl\\lib\\site-packages\\gym\\envs\\registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "\n",
      "target_params_replaced\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Double DQN & Natural DQN comparison,\n",
    "The Pendulum example.\n",
    "View more on my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "Using:\n",
    "Tensorflow: 1.0\n",
    "gym: 0.8.0\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import gym\n",
    "#from RL_brain import DoubleDQN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "env = gym.make('Pendulum-v0')\n",
    "env = env.unwrapped\n",
    "env.seed(1)\n",
    "MEMORY_SIZE = 3000\n",
    "ACTION_SPACE = 11\n",
    "\n",
    "sess = tf.Session()\n",
    "with tf.variable_scope('Natural_DQN'):\n",
    "    natural_DQN = DoubleDQN(\n",
    "        n_actions=ACTION_SPACE, n_features=3, memory_size=MEMORY_SIZE,\n",
    "        e_greedy_increment=0.001, double_q=False, sess=sess\n",
    "    )\n",
    "\n",
    "with tf.variable_scope('Double_DQN'):\n",
    "    double_DQN = DoubleDQN(\n",
    "        n_actions=ACTION_SPACE, n_features=3, memory_size=MEMORY_SIZE,\n",
    "        e_greedy_increment=0.001, double_q=True, sess=sess, output_graph=True)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "def train(RL):\n",
    "    total_steps = 0\n",
    "    observation = env.reset()\n",
    "    while True:\n",
    "        # if total_steps - MEMORY_SIZE > 8000: env.render()\n",
    "\n",
    "        action = RL.choose_action(observation)\n",
    "\n",
    "        f_action = (action-(ACTION_SPACE-1)/2)/((ACTION_SPACE-1)/4)   # convert to [-2 ~ 2] float actions\n",
    "        observation_, reward, done, info = env.step(np.array([f_action]))\n",
    "\n",
    "        reward /= 10     # normalize to a range of (-1, 0). r = 0 when get upright\n",
    "        # the Q target at upright state will be 0, because Q_target = r + gamma * Qmax(s', a') = 0 + gamma * 0\n",
    "        # so when Q at this state is greater than 0, the agent overestimates the Q. Please refer to the final result.\n",
    "\n",
    "        RL.store_transition(observation, action, reward, observation_)\n",
    "\n",
    "        if total_steps > MEMORY_SIZE:   # learning\n",
    "            RL.learn()\n",
    "\n",
    "        if total_steps - MEMORY_SIZE > 6000:   # stop game\n",
    "            break\n",
    "\n",
    "        observation = observation_\n",
    "        total_steps += 1\n",
    "    return RL.q\n",
    "\n",
    "q_natural = train(natural_DQN)\n",
    "q_double = train(double_DQN)\n",
    "\n",
    "plt.plot(np.array(q_natural), c='r', label='natural')\n",
    "plt.plot(np.array(q_double), c='b', label='double')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Q eval')\n",
    "plt.xlabel('training steps')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(q_natural), c='r', label='natural')\n",
    "plt.plot(np.array(q_double), c='b', label='double')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Q eval')\n",
    "plt.xlabel('training steps')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "# 程序仿真部分\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "class Area():\n",
    "    def __init__(self, n, a_id):\n",
    "        self.a_id = a_id\n",
    "        self.normal_bike = n\n",
    "        self.broken_bike = 0\n",
    "\n",
    "    def move(self):\n",
    "        self.normal_bike -= 1\n",
    "        self.broken_bike += 1\n",
    "\n",
    "\n",
    "def binaryInsert(target, events):\n",
    "    for event in events:\n",
    "        if event >= target[-1]:\n",
    "            target.append(event)\n",
    "        else:\n",
    "            l, mid, r = 0, int(len(target) / 2), len(target) - 1\n",
    "            while 1:\n",
    "                if r - l == 1:\n",
    "                    target.insert(r, event)\n",
    "                    break\n",
    "                else:\n",
    "                    if event > target[mid]:\n",
    "                        l = mid\n",
    "                        mid = int((r + l) / 2)\n",
    "                    else:\n",
    "                        r = mid\n",
    "                        mid = int((r + l) / 2)\n",
    "\n",
    "\n",
    "def simulate(N, R, A, Q, P, t_limit):\n",
    "    '''\n",
    "    N: initial number of bikes in the network\n",
    "    R: rates of arriving and departing for each node\n",
    "    A: number of Areas\n",
    "    Q: matrix of tansitition probability\n",
    "    P: policy of dealing with broken bikes\n",
    "\n",
    "    T: system clock\n",
    "    scheduler: stack of upcoming events,[t, event_type, area], 1 for customer arrival, 2 for bike arrival\n",
    "    \n",
    "    stat: record of system state parameters\n",
    "    loss: record of customer loss\n",
    "    '''\n",
    "\n",
    "    # initiate\n",
    "    T = 0\n",
    "    #stat, S = pd.DataFrame(columns=['type', 'place', 't']), 0\n",
    "    loss, L = pd.DataFrame(columns=['place', 't']), 0\n",
    "    broken, B = pd.DataFrame(columns=['place', 'ng', 'nb', 't']), 0\n",
    "\n",
    "    # initiation of instances of Area and scheduler\n",
    "    scheduler = []\n",
    "    a = []\n",
    "    for i in range(A):\n",
    "        a.append(Area(N / A, i))\n",
    "        scheduler.append([np.random.exponential(1/R.loc[i].cus_arr), 1, a[i]])\n",
    "    scheduler.sort()\n",
    "\n",
    "    # system running\n",
    "    while T < t_limit:\n",
    "        \n",
    "        T = scheduler[0][0]\n",
    "        if scheduler[0][1] == 1:\n",
    "            #stat.loc[S], S = [scheduler[0][1], scheduler[0][2].a_id, T], S+1\n",
    "            if scheduler[0][2].normal_bike == 0:\n",
    "                # this is a loss\n",
    "                loss.loc[L], L = [scheduler[0][2].a_id, T], L+1\n",
    "                event = [T + np.random.exponential(1/R.loc[scheduler[0][2].a_id].cus_arr), 1, scheduler[0][2]]\n",
    "                binaryInsert(scheduler, [event])\n",
    "            else:\n",
    "                target = np.random.choice(np.arange(A+1), 1, p=Q[scheduler[0][2].a_id])\n",
    "                if target == A:\n",
    "                    broken.loc[B], B = [scheduler[0][2].a_id, scheduler[0][2].normal_bike, scheduler[0][2].broken_bike, T], B+1\n",
    "                    scheduler[0][2].move()\n",
    "                    continue\n",
    "                else:\n",
    "                    scheduler[0][2].normal_bike -= 1\n",
    "                    event1 = [T + np.random.exponential(1/R.loc[scheduler[0][2].a_id].ride), 2, a[target[0]]]\n",
    "                    event2 = [T + np.random.exponential(1/R.loc[scheduler[0][2].a_id].cus_arr), 1, scheduler[0][2]]\n",
    "                    binaryInsert(scheduler, [event1, event2])\n",
    "        else:\n",
    "            #stat.loc[S], S = [scheduler[0][1], scheduler[0][2].a_id, T], S+1\n",
    "            scheduler[0][2].normal_bike += 1\n",
    "        scheduler.pop(0)\n",
    "        \n",
    "    #return stat\n",
    "    #return loss, broken\n",
    "    return loss.shape[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(1)\n",
    "    N = 360\n",
    "    A = 9\n",
    "    R = pd.DataFrame({'cus_arr': [5] * A, 'ride': [10] * A}, index=range(A))\n",
    "    Q = [np.random.rand(A+1) for i in range(A)]\n",
    "    Q = [q / sum(q) for q in Q]\n",
    "    #Q = [[0,0.9,0.1], [0.9,0,0.1]]\n",
    "    P = 0\n",
    "    time_limit = 60\n",
    "\n",
    "    %time print(simulate(N, R, A, Q, P, time_limit))\n",
    "    #result = simulate(N, R, A, Q, P, time_limit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>ng</th>\n",
       "      <th>nb</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.195615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.284938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.381245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.404823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.900593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.654301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.654301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.712419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.048524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.330231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.337565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.337565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.510352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.919958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.427655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.493495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.805975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.976089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.249872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.531246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.643086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>76.295331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.671493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>78.480910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>78.724525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>78.760689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>78.831924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79.455108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>79.542344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>79.921546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>80.119770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>80.527938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.343668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>81.573442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>81.854379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>82.034053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>82.237989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>83.074325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>83.274879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>83.787811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>84.301469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>85.693961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>85.786078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>86.220673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>86.220673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>86.857906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.139085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>88.123091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>88.716433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>88.987683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>92.262437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     place    ng    nb          t\n",
       "0      0.0  40.0   0.0   0.024376\n",
       "1      4.0  40.0   0.0   0.104896\n",
       "2      5.0  40.0   0.0   0.288923\n",
       "3      1.0  47.0   0.0   0.597114\n",
       "4      2.0  36.0   0.0   0.750627\n",
       "5      6.0  43.0   0.0   0.836530\n",
       "6      5.0  39.0   1.0   0.938654\n",
       "7      2.0  33.0   1.0   0.964442\n",
       "8      0.0  43.0   1.0   1.195615\n",
       "9      2.0  32.0   2.0   1.284938\n",
       "10     0.0  41.0   2.0   1.381245\n",
       "11     2.0  31.0   3.0   1.404823\n",
       "12     0.0  37.0   3.0   1.900593\n",
       "13     2.0  27.0   4.0   2.010810\n",
       "14     2.0  24.0   5.0   2.654301\n",
       "15     2.0  23.0   6.0   2.654301\n",
       "16     4.0  29.0   1.0   2.712419\n",
       "17     5.0  40.0   2.0   3.048524\n",
       "18     3.0  40.0   0.0   3.330231\n",
       "19     0.0  36.0   4.0   3.337565\n",
       "20     0.0  35.0   5.0   3.337565\n",
       "21     0.0  33.0   6.0   3.510352\n",
       "22     3.0  38.0   1.0   3.919958\n",
       "23     8.0  43.0   0.0   4.427655\n",
       "24     3.0  35.0   2.0   4.493495\n",
       "25     5.0  40.0   3.0   4.805975\n",
       "26     7.0  40.0   0.0   4.976089\n",
       "27     1.0  49.0   1.0   5.249872\n",
       "28     6.0  64.0   1.0   5.531246\n",
       "29     3.0  32.0   3.0   5.643086\n",
       "..     ...   ...   ...        ...\n",
       "330    0.0   1.0  45.0  76.295331\n",
       "331    3.0   1.0  46.0  76.671493\n",
       "332    2.0   1.0  32.0  78.480910\n",
       "333    3.0   6.0  47.0  78.724525\n",
       "334    3.0   4.0  48.0  78.760689\n",
       "335    7.0   2.0  46.0  78.831924\n",
       "336    3.0   3.0  49.0  79.455108\n",
       "337    0.0   2.0  46.0  79.542344\n",
       "338    5.0   1.0  50.0  79.921546\n",
       "339    8.0   1.0  25.0  80.119770\n",
       "340    7.0   1.0  47.0  80.527938\n",
       "341    6.0   1.0  56.0  81.343668\n",
       "342    3.0   2.0  50.0  81.573442\n",
       "343    6.0   3.0  57.0  81.854379\n",
       "344    1.0   9.0  24.0  82.034053\n",
       "345    2.0   1.0  33.0  82.237989\n",
       "346    2.0   1.0  34.0  83.074325\n",
       "347    6.0   1.0  58.0  83.274879\n",
       "348    7.0   1.0  48.0  83.787811\n",
       "349    5.0   1.0  51.0  84.301469\n",
       "350    8.0   1.0  26.0  85.693961\n",
       "351    2.0   1.0  35.0  85.786078\n",
       "352    3.0   2.0  51.0  86.220673\n",
       "353    3.0   1.0  52.0  86.220673\n",
       "354    3.0   1.0  53.0  86.857906\n",
       "355    4.0   1.0   6.0  87.139085\n",
       "356    5.0   1.0  52.0  88.123091\n",
       "357    5.0   1.0  53.0  88.716433\n",
       "358    2.0   1.0  36.0  88.987683\n",
       "359    8.0   1.0  27.0  92.262437\n",
       "\n",
       "[360 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
